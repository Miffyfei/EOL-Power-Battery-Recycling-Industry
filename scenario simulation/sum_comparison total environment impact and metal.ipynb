{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-15T21:02:47.581520Z",
     "start_time": "2025-10-15T21:02:05.056930Z"
    }
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Consolidate five workbooks into 52 combined scenarios and produce:\n",
    "1) Provincial annual sums\n",
    "2) National annual sums\n",
    "3) 2020–2030 totals (national)\n",
    "4) Province-level Δ vs BS+BS (2020–2030)\n",
    "5) National Δ vs BS+BS (2020–2030)\n",
    "6) (Optional) Five city-level merged sheets with exact headers\n",
    "\n",
    "Place this script in the same folder as the 5 Excel files or edit BASE_DIR.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "\n",
    "# ========= USER SETTINGS =========\n",
    "BASE_DIR = Path(\"./output data\")   # <- adjust if needed\n",
    "OUTFILE  = BASE_DIR / \"Consolidated_52_scenarios_environment with transport_metal.xlsx\"\n",
    "WRITE_CITY_LEVEL = False   # True = also write the 5 big city-level merged sheets\n",
    "\n",
    "FILES = {\n",
    "    # family : (filename, [sheet names], demand-col-name inside that workbook)\n",
    "    \"AR\": (\"Environmental impact and metal recovery results under AR scenario.xlsx\",\n",
    "           [\"AR1 scenario\",\"AR2 scenario\",\"AR3 scenario\"], \"AR Scenario\"),\n",
    "    \"BS\": (\"Environmental impact and metal recovery results under BS scenario.xlsx\",\n",
    "           [\"Baseline scenario\"], None),\n",
    "    \"ES\": (\"Environmental impact and metal recovery results under ES scenario.xlsx\",\n",
    "           [\"ES1 scenario\",\"ES2 scenario\",\"ES3 scenario\"], \"ES\"),\n",
    "    \"SU\": (\"Environmental impact and metal recovery results under SU scenario.xlsx\",\n",
    "           [\"SU1 scenario\",\"SU2 scenario\",\"SU3 scenario\"], \"SU Scenario\"),\n",
    "    \"TO\": (\"Environmental impact and metal recovery results under TO scenario.xlsx\",\n",
    "           [\"TO1 scenario\",\"TO2 scenario\",\"TO3 scenario\"], \"TO Scenario\"),\n",
    "}\n",
    "\n",
    "NUM_COLS = [\n",
    "    \"Abiotic depletion\",\"Abiotic depletion (fossil fuels)\",\"Acidification\",\"Eutrophication\",\n",
    "    \"Fresh water aquatic ecotox.\",\"Global warming (GWP100a)\",\"Human toxicity\",\n",
    "    \"Marine aquatic ecotoxicity\",\"Ozone layer depletion (ODP)\",\"Photochemical oxidation\",\n",
    "    \"Terrestrial ecotoxicity\",\"lithium\",\"nickel\",\"cobalt\",\"manganese\"\n",
    "]\n",
    "\n",
    "# ---- optional city-sheet column orders (exactly as you gave) ----\n",
    "CITY_COLS = {\n",
    "    \"SU\": [\"SU Scenario\",\"Scenario\",\"Year\",\"Province\",\"City\",\"Code\",\"Battery type\",\"SU Ratio\"] + NUM_COLS,\n",
    "    \"AR\": [\"AR Scenario\",\"Scenario\",\"Year\",\"Province\",\"City\",\"Code\",\"Battery type\",\"AR Ratio\"] + NUM_COLS,\n",
    "    \"ES\": [\"ES\",\"Scenario\",\"Year\",\"Province\",\"City\",\"Code\",\"Battery type\"] + NUM_COLS,\n",
    "    \"BS\": [\"Scenario\",\"Year\",\"Province\",\"City\",\"Code\",\"Battery type\"] + NUM_COLS,\n",
    "    \"TO\": [\"TO Scenario\",\"Scenario\",\"Year\",\"Province\",\"City\",\"Code\",\"Battery type\"] + NUM_COLS,\n",
    "}\n",
    "\n",
    "def _add_vec(acc, vals):\n",
    "    for i, v in enumerate(vals):\n",
    "        if v is None or v == \"\":\n",
    "            continue\n",
    "        acc[i] += float(v)\n",
    "\n",
    "# ---- streaming aggregation (fast & memory-light) ----\n",
    "prov_annual = defaultdict(lambda: [0.0]*len(NUM_COLS))\n",
    "nat_annual  = defaultdict(lambda: [0.0]*len(NUM_COLS))\n",
    "totals_nat  = defaultdict(lambda: [0.0]*len(NUM_COLS))\n",
    "prov_total  = defaultdict(lambda: [0.0]*len(NUM_COLS))\n",
    "bsbs_prov   = defaultdict(lambda: [0.0]*len(NUM_COLS))\n",
    "bsbs_nat    = [0.0]*len(NUM_COLS)\n",
    "\n",
    "for fam, (fname, sheets, fam_col) in FILES.items():\n",
    "    wb = load_workbook(BASE_DIR / fname, read_only=True, data_only=True)\n",
    "    for s in sheets:\n",
    "        ws = wb[s]\n",
    "        header = list(next(ws.iter_rows(min_row=1, max_row=1, values_only=True)))\n",
    "        col_idx = {name: i for i, name in enumerate(header)}\n",
    "\n",
    "        # Required columns present?\n",
    "        req = [\"Scenario\",\"Year\",\"Province\"] + ([fam_col] if fam_col else [])\n",
    "        missing = [c for c in req if c not in col_idx]\n",
    "        if missing:\n",
    "            raise RuntimeError(f\"Missing columns {missing} in {fname} / {s}\")\n",
    "\n",
    "        idx_supp = col_idx[\"Scenario\"]\n",
    "        idx_year = col_idx[\"Year\"]\n",
    "        idx_prov = col_idx[\"Province\"]\n",
    "        idx_demd = col_idx.get(fam_col) if fam_col else None\n",
    "        idx_nums = [col_idx.get(n) for n in NUM_COLS]   # may all exist, as designed\n",
    "\n",
    "        for row in ws.iter_rows(min_row=2, values_only=True):\n",
    "            sup = row[idx_supp]\n",
    "            yr  = row[idx_year]\n",
    "            prv = row[idx_prov]\n",
    "            if sup is None or yr is None or prv is None:\n",
    "                continue\n",
    "            sup = str(sup)\n",
    "            year = int(yr)\n",
    "            prov = str(prv)\n",
    "            demd = \"BS\" if fam == \"BS\" else str(row[idx_demd])\n",
    "            combined = f\"{sup}+{demd}\"\n",
    "            vals = [row[i] if i is not None else None for i in idx_nums]\n",
    "\n",
    "            _add_vec(prov_annual[(combined, sup, demd, year, prov)], vals)\n",
    "            _add_vec(nat_annual[(combined, sup, demd, year)], vals)\n",
    "            _add_vec(totals_nat[(combined, sup, demd)], vals)\n",
    "            _add_vec(prov_total[(combined, sup, demd, prov)], vals)\n",
    "\n",
    "            # baseline accumulation: BS supply + BS demand inside BS workbook\n",
    "            if fam == \"BS\" and sup == \"BS\":\n",
    "                _add_vec(bsbs_prov[(prov,)], vals)\n",
    "                _add_vec(bsbs_nat, vals)\n",
    "\n",
    "# ---- dicts -> DataFrames ----\n",
    "def dict_to_df(dct, key_cols):\n",
    "    rows = [list(k)+v for k, v in dct.items()]\n",
    "    return pd.DataFrame(rows, columns=key_cols + NUM_COLS)\n",
    "\n",
    "df_prov_annual = dict_to_df(prov_annual, [\"Combined scenario\",\"Scenario\",\"Demand scenario\",\"Year\",\"Province\"])\n",
    "df_nat_annual  = dict_to_df(nat_annual,  [\"Combined scenario\",\"Scenario\",\"Demand scenario\",\"Year\"])\n",
    "df_totals_nat  = dict_to_df(totals_nat,  [\"Combined scenario\",\"Scenario\",\"Demand scenario\"])\n",
    "df_prov_total  = dict_to_df(prov_total,  [\"Combined scenario\",\"Scenario\",\"Demand scenario\",\"Province\"])\n",
    "df_bsbs_prov   = dict_to_df(bsbs_prov,   [\"Province\"])\n",
    "\n",
    "# ---- build Δ vs BS+BS (provincial & national) ----\n",
    "prov_diff = df_prov_total.merge(\n",
    "    df_bsbs_prov.add_suffix(\" (BS+BS)\"),\n",
    "    left_on=\"Province\", right_on=\"Province (BS+BS)\",\n",
    "    how=\"left\"\n",
    ")\n",
    "for c in NUM_COLS:\n",
    "    prov_diff[f\"{c} (Δ vs BS+BS)\"] = prov_diff[c] - prov_diff[f\"{c} (BS+BS)\"]\n",
    "prov_diff_out = prov_diff[\n",
    "    [\"Combined scenario\",\"Scenario\",\"Demand scenario\",\"Province\"]\n",
    "    + [f\"{c} (Δ vs BS+BS)\" for c in NUM_COLS]\n",
    "]\n",
    "\n",
    "bsbs_nat_row = pd.Series(bsbs_nat, index=NUM_COLS)\n",
    "nat_diff_out = df_totals_nat.copy()\n",
    "for c in NUM_COLS:\n",
    "    nat_diff_out[f\"{c} (Δ vs BS+BS)\"] = nat_diff_out[c] - bsbs_nat_row[c]\n",
    "\n",
    "# ---- (optional) city-level merged sheets with exact headers ----\n",
    "city_frames = {}\n",
    "if WRITE_CITY_LEVEL:\n",
    "    for fam, (fname, sheets, fam_col) in FILES.items():\n",
    "        fam_frames = []\n",
    "        for s in sheets:\n",
    "            df = pd.read_excel(BASE_DIR / fname, sheet_name=s)\n",
    "            # Order columns to the requested header if available; otherwise keep intersect\n",
    "            wanted = CITY_COLS[\"BS\"]  # default\n",
    "            if fam in CITY_COLS: wanted = CITY_COLS[fam]\n",
    "            cols = [c for c in wanted if c in df.columns]\n",
    "            df = df[cols].copy()\n",
    "            fam_frames.append(df)\n",
    "        city_frames[fam] = pd.concat(fam_frames, ignore_index=True)\n",
    "\n",
    "# ---- write everything ----\n",
    "with pd.ExcelWriter(OUTFILE, engine=\"openpyxl\") as w:\n",
    "    df_prov_annual.to_excel(w, sheet_name=\"Provincial annual sums\", index=False)\n",
    "    df_nat_annual.to_excel(w,  sheet_name=\"National annual sums\",   index=False)\n",
    "    df_totals_nat.to_excel(w,  sheet_name=\"2020–2030 totals (nat.)\", index=False)\n",
    "    prov_diff_out.to_excel(w,  sheet_name=\"Δ 2020–2030 vs BS+BS (prov)\", index=False)\n",
    "    nat_diff_out[[\"Combined scenario\",\"Scenario\",\"Demand scenario\"]\n",
    "                 + [f\"{c} (Δ vs BS+BS)\" for c in NUM_COLS]].to_excel(\n",
    "        w, sheet_name=\"Δ 2020–2030 vs BS+BS (nat)\", index=False\n",
    "    )\n",
    "    if WRITE_CITY_LEVEL:\n",
    "        # exact headers per your request\n",
    "        if \"BS\" in city_frames: city_frames[\"BS\"].to_excel(w, sheet_name=\"BS – merged (city)\", index=False)\n",
    "        if \"AR\" in city_frames: city_frames[\"AR\"].to_excel(w, sheet_name=\"AR – merged (city)\", index=False)\n",
    "        if \"ES\" in city_frames: city_frames[\"ES\"].to_excel(w, sheet_name=\"ES – merged (city)\", index=False)\n",
    "        if \"SU\" in city_frames: city_frames[\"SU\"].to_excel(w, sheet_name=\"SU – merged (city)\", index=False)\n",
    "        if \"TO\" in city_frames: city_frames[\"TO\"].to_excel(w, sheet_name=\"TO – merged (city)\", index=False)\n",
    "\n",
    "print(f\"Done: {OUTFILE}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: output data\\Consolidated_52_scenarios_environment_metal.xlsx\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T22:02:36.305356Z",
     "start_time": "2025-10-15T22:02:23.452168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Fixed code ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Environmental and metal columns (consistent with main script)\n",
    "ENV_COLS = [\n",
    "    \"Abiotic depletion\",\"Abiotic depletion (fossil fuels)\",\"Acidification\",\"Eutrophication\",\n",
    "    \"Fresh water aquatic ecotox.\",\"Global warming (GWP100a)\",\"Human toxicity\",\n",
    "    \"Marine aquatic ecotoxicity\",\"Ozone layer depletion (ODP)\",\"Photochemical oxidation\",\"Terrestrial ecotoxicity\"\n",
    "]\n",
    "METAL_COLS = [\"lithium\",\"nickel\",\"cobalt\",\"manganese\"]\n",
    "NUM_COLS = ENV_COLS + METAL_COLS\n",
    "\n",
    "# Define output file path\n",
    "BASE_DIR = Path(\"./output data\")  # Adjust according to actual situation\n",
    "OUTFILE = BASE_DIR / \"Consolidated_52_scenarios_environment with transport_metal.xlsx\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def sum_with_transport(df: pd.DataFrame, env_cols=ENV_COLS):\n",
    "    \"\"\"\n",
    "    Add processing stage + transport stage column by column:\n",
    "    For each environmental column c:\n",
    "      If 'c (transport)' column exists, then total[c] = df[c] + df['c (transport)'];\n",
    "      Otherwise total[c] = df[c] (or 0 if doesn't exist).\n",
    "    Metal columns don't add transport, keep original values.\n",
    "    Returns: DataFrame after addition (removing * (transport) columns)\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    # Ensure base columns exist (fill with 0 if not)\n",
    "    for c in env_cols:\n",
    "        if c not in out.columns:\n",
    "            out[c] = 0.0\n",
    "        base = pd.to_numeric(out[c], errors=\"coerce\").fillna(0.0)\n",
    "        tcol = f\"{c} (transport)\"\n",
    "        if tcol in out.columns:\n",
    "            trans = pd.to_numeric(out[tcol], errors=\"coerce\").fillna(0.0)\n",
    "            out[c] = base + trans\n",
    "        else:\n",
    "            out[c] = base\n",
    "    # Metal columns keep original values (fill with 0 if not exist)\n",
    "    for c in METAL_COLS:\n",
    "        if c not in out.columns:\n",
    "            out[c] = 0.0\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\").fillna(0.0)\n",
    "    # Remove transport intermediate columns\n",
    "    drop_cols = [c for c in out.columns if c.endswith(\" (transport)\")]\n",
    "    if drop_cols:\n",
    "        out = out.drop(columns=drop_cols)\n",
    "    return out\n",
    "\n",
    "# ---- 1) Provincial annual (with transport) ----\n",
    "# Re-merge once here to ensure getting '(transport)' columns\n",
    "_key_prov_yr = [\"Scenario\",\"Year\",\"Province\"]\n",
    "left = df_prov_annual.merge(\n",
    "    trans_prov_annual, on=_key_prov_yr, how=\"left\", suffixes=(\"\",\" (transport)\")\n",
    ").fillna(0.0)\n",
    "df_prov_annual_transport = sum_with_transport(left, ENV_COLS)\n",
    "\n",
    "# ---- 2) National annual (with transport) ----\n",
    "_key_nat_yr = [\"Scenario\",\"Year\"]\n",
    "left = df_nat_annual.merge(\n",
    "    trans_nat_annual, on=_key_nat_yr, how=\"left\", suffixes=(\"\",\" (transport)\")\n",
    ").fillna(0.0)\n",
    "df_nat_annual_transport = sum_with_transport(left, ENV_COLS)\n",
    "\n",
    "# ---- 3) Provincial 2020–2030 total (with transport) ----\n",
    "_key_prov = [\"Scenario\",\"Province\"]\n",
    "left = df_prov_total.merge(\n",
    "    trans_prov_total, on=_key_prov, how=\"left\", suffixes=(\"\",\" (transport)\")\n",
    ").fillna(0.0)\n",
    "df_prov_total_transport = sum_with_transport(left, ENV_COLS)\n",
    "\n",
    "# ---- 4) National 2020–2030 total (with transport) ----\n",
    "left = df_totals_nat.merge(\n",
    "    trans_nat_total, on=[\"Scenario\"], how=\"left\", suffixes=(\"\",\" (transport)\")\n",
    ").fillna(0.0)\n",
    "df_totals_nat_transport = sum_with_transport(left, ENV_COLS)\n",
    "\n",
    "# ---- 5) Rebuild BS+BS (with transport) as baseline ----\n",
    "# First add BS transport totals to provincial/national baseline\n",
    "bs_trans_prov = trans_prov_total[trans_prov_total[\"Scenario\"]==\"BS\"].drop(columns=[\"Scenario\"]).copy()\n",
    "bs_trans_nat  = trans_nat_total[trans_nat_total[\"Scenario\"]==\"BS\"].drop(columns=[\"Scenario\"]).copy()\n",
    "\n",
    "df_bsbs_prov_env = df_bsbs_prov.copy()\n",
    "for c in ENV_COLS:\n",
    "    tc = bs_trans_prov.set_index(\"Province\")[c]\n",
    "    df_bsbs_prov_env[c] = pd.to_numeric(df_bsbs_prov_env[c], errors=\"coerce\").fillna(0.0) + df_bsbs_prov_env[\"Province\"].map(tc).fillna(0.0)\n",
    "\n",
    "bsbs_nat_with_trans = bsbs_nat_row.copy()\n",
    "for c in ENV_COLS:\n",
    "    add_val = float(bs_trans_nat[c].iloc[0]) if not bs_trans_nat.empty else 0.0\n",
    "    base_val = pd.to_numeric(bsbs_nat_with_trans[c], errors=\"coerce\")\n",
    "    if pd.isna(base_val):\n",
    "        base_val = 0.0\n",
    "    bsbs_nat_with_trans[c] = float(base_val) + add_val\n",
    "\n",
    "# ---- 6) Calculate Δ & Δ% (with transport), including metal change ratios ----\n",
    "def delta_and_ratio(df_vals: pd.DataFrame, df_bs_ref: pd.DataFrame, key_cols):\n",
    "    merged = df_vals.merge(\n",
    "        df_bs_ref.add_suffix(\" (BS+BS)\"),\n",
    "        left_on=key_cols, right_on=[k+\" (BS+BS)\" for k in key_cols],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    out = merged[key_cols + NUM_COLS].copy()\n",
    "\n",
    "    # Δ\n",
    "    for c in NUM_COLS:\n",
    "        out[f\"{c} (Δ vs BS+BS) (+transport)\"] = pd.to_numeric(out[c], errors=\"coerce\").fillna(0.0) - \\\n",
    "                                                pd.to_numeric(merged[f\"{c} (BS+BS)\"], errors=\"coerce\").fillna(0.0)\n",
    "    # Δ% environmental\n",
    "    for c in ENV_COLS:\n",
    "        base = pd.to_numeric(merged[f\"{c} (BS+BS)\"], errors=\"coerce\")\n",
    "        base = base.replace(0, np.nan)\n",
    "        out[f\"{c} (Δ% vs BS+BS) (+transport)\"] = (out[f\"{c} (Δ vs BS+BS) (+transport)\"] / base).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "    # Metal Δ%\n",
    "    for c in METAL_COLS:\n",
    "        base = pd.to_numeric(merged[f\"{c} (BS+BS)\"], errors=\"coerce\")\n",
    "        base = base.replace(0, np.nan)\n",
    "        out[f\"{c} (Δ% vs BS+BS) (+transport)\"] = (out[f\"{c} (Δ vs BS+BS) (+transport)\"] / base).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return out\n",
    "\n",
    "# Provincial baseline reference (create DF with placeholder keys from df_bsbs_prov_env)\n",
    "bs_ref_prov_df = pd.DataFrame({\n",
    "    \"Combined scenario\": [\"BS+BS\"]*len(df_bsbs_prov_env),\n",
    "    \"Scenario\": [\"BS\"]*len(df_bsbs_prov_env),\n",
    "    \"Demand scenario\": [\"BS\"]*len(df_bsbs_prov_env),\n",
    "    \"Province\": df_bsbs_prov_env[\"Province\"]\n",
    "})\n",
    "for c in NUM_COLS:\n",
    "    bs_ref_prov_df[c] = pd.to_numeric(df_bsbs_prov_env[c], errors=\"coerce\").fillna(0.0).values\n",
    "\n",
    "prov_keys = [\"Combined scenario\",\"Scenario\",\"Demand scenario\",\"Province\"]\n",
    "# Ensure all key columns have consistent data types\n",
    "key_columns = [\"Combined scenario\", \"Scenario\", \"Demand scenario\", \"Province\"]\n",
    "\n",
    "for col in key_columns:\n",
    "    if col in df_prov_total_transport.columns:\n",
    "        df_prov_total_transport[col] = df_prov_total_transport[col].astype(str)\n",
    "    if col in bs_ref_prov_df.columns:\n",
    "        bs_ref_prov_df[col] = bs_ref_prov_df[col].astype(str)\n",
    "\n",
    "# Execute provincial delta_and_ratio function (call only once)\n",
    "prov_delta_ratio_transport = delta_and_ratio(\n",
    "    df_vals=df_prov_total_transport[prov_keys + NUM_COLS].copy(),\n",
    "    df_bs_ref=bs_ref_prov_df[[\"Combined scenario\", \"Scenario\", \"Demand scenario\", \"Province\"] + NUM_COLS].copy(),\n",
    "    key_cols=prov_keys\n",
    ")\n",
    "\n",
    "# National baseline reference (Series -> DF)\n",
    "bs_ref_nat = pd.DataFrame([[\"BS+BS\",\"BS\",\"BS\"] + list(pd.to_numeric(bsbs_nat_with_trans[NUM_COLS], errors=\"coerce\").fillna(0.0).values)],\n",
    "                          columns=[\"Combined scenario\",\"Scenario\",\"Demand scenario\"] + NUM_COLS)\n",
    "\n",
    "# Ensure national key columns have consistent data types\n",
    "nat_key_columns = [\"Combined scenario\", \"Scenario\", \"Demand scenario\"]\n",
    "\n",
    "for col in nat_key_columns:\n",
    "    if col in df_totals_nat_transport.columns:\n",
    "        df_totals_nat_transport[col] = df_totals_nat_transport[col].astype(str)\n",
    "    if col in bs_ref_nat.columns:\n",
    "        bs_ref_nat[col] = bs_ref_nat[col].astype(str)\n",
    "\n",
    "# Execute national delta_and_ratio function (call only once)\n",
    "nat_delta_ratio_transport = delta_and_ratio(\n",
    "    df_vals=df_totals_nat_transport[nat_key_columns + NUM_COLS].copy(),\n",
    "    df_bs_ref=bs_ref_nat[nat_key_columns + NUM_COLS].copy(),\n",
    "    key_cols=nat_key_columns\n",
    ")\n",
    "\n",
    "# ---- 7) Write results to same OUTFILE (append/overwrite same sheets) ----\n",
    "try:\n",
    "    with pd.ExcelWriter(OUTFILE, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as w:\n",
    "        df_prov_annual_transport.to_excel(w, sheet_name=\"Provincial annual sums (+transport)\", index=False)\n",
    "        df_nat_annual_transport.to_excel(w, sheet_name=\"National annual sums (+transport)\", index=False)\n",
    "        df_prov_total_transport.to_excel(w, sheet_name=\"2020–2030 totals (prov., +transport)\", index=False)\n",
    "        df_totals_nat_transport.to_excel(w, sheet_name=\"2020–2030 totals (nat., +transport)\", index=False)\n",
    "        prov_delta_ratio_transport.to_excel(w, sheet_name=\"Δ 2020–2030 vs BS+BS (prov, +transport+ratio)\", index=False)\n",
    "        nat_delta_ratio_transport.to_excel(w, sheet_name=\"Δ 2020–2030 vs BS+BS (nat, +transport+ratio)\", index=False)\n",
    "    \n",
    "    print(\"✅ Fixed: transport merged and Δ/ratios recomputed without KeyError.\")\n",
    "except FileNotFoundError:\n",
    "    # If file doesn't exist, create new file\n",
    "    with pd.ExcelWriter(OUTFILE, engine=\"openpyxl\") as w:\n",
    "        df_prov_annual_transport.to_excel(w, sheet_name=\"Provincial annual sums (+transport)\", index=False)\n",
    "        df_nat_annual_transport.to_excel(w, sheet_name=\"National annual sums (+transport)\", index=False)\n",
    "        df_prov_total_transport.to_excel(w, sheet_name=\"2020–2030 totals (prov., +transport)\", index=False)\n",
    "        df_totals_nat_transport.to_excel(w, sheet_name=\"2020–2030 totals (nat., +transport)\", index=False)\n",
    "        prov_delta_ratio_transport.to_excel(w, sheet_name=\"Δ 2020–2030 vs BS+BS (prov, +transport+ratio)\", index=False)\n",
    "        nat_delta_ratio_transport.to_excel(w, sheet_name=\"Δ 2020–2030 vs BS+BS (nat, +transport+ratio)\", index=False)\n",
    "    \n",
    "    print(\"✅ Fixed: transport merged and Δ/ratios recomputed. Created new file.\")"
   ],
   "id": "f392bd6c9ddde6b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pengf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed: transport merged and Δ/ratios recomputed without KeyError.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aaafa5f1a6872567"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
